{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I052\n",
        "\n",
        "Reya Oberoi\n",
        "\n",
        "NLP Assignment : N-gram modelling"
      ],
      "metadata": {
        "id": "diSJgyN8tyul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UgeoOy2onZoa",
        "outputId": "7ba6e360-6f98-4430-e499-c83137495359"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataet download, text pre-processing and Tokenization"
      ],
      "metadata": {
        "id": "pat0Ba4eo0ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\""
      ],
      "metadata": {
        "id": "8WiJMrxWqLmw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = requests.get(url).text.lower()\n",
        "\n",
        "# Remove header and footer\n",
        "start_marker = \"*** start of the project gutenberg ebook\"\n",
        "end_marker = \"end of the project gutenberg ebook\"\n",
        "raw_text = raw_text[raw_text.find(start_marker) + len(start_marker):raw_text.find(end_marker)]\n",
        "\n",
        "# Tokenize and clean the text\n",
        "tokens = word_tokenize(raw_text)\n",
        "tokens = [token for token in tokens if re.match(r'^[a-z]+$', token)]\n",
        "print(\"Data loaded and preprocessed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "S68BtytGqOL5",
        "outputId": "77d0305b-ffca-4ba1-ec36-b42c1c67f446"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded and preprocessed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N-GRAM MODELING"
      ],
      "metadata": {
        "id": "uQ1vC5QspCVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ngram modeling with laplace smoothing\n",
        "def build_ngram_model(tokens, n, smoothing=1):\n",
        "    model = defaultdict(lambda: defaultdict(lambda: smoothing))\n",
        "    for i in range(len(tokens) - n):\n",
        "        history = tuple(tokens[i:i + n])\n",
        "        next_word = tokens[i + n]\n",
        "        model[history][next_word] += 1\n",
        "\n",
        "    for history in model:\n",
        "        total_count = sum(model[history].values())\n",
        "        for next_word in model[history]:\n",
        "            model[history][next_word] /= total_count\n",
        "    return model"
      ],
      "metadata": {
        "id": "yF94OmjOpKAi"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Generation"
      ],
      "metadata": {
        "id": "2bia4mpkpLWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SENTENCE GENERATION WITH BACK-OFF\n",
        "def generate_sentence_with_backoff(start_words, max_length=15):\n",
        "    words = start_words.lower().split()\n",
        "\n",
        "    # Pad history with None if start_words are fewer than 3\n",
        "    if len(words) < 3:\n",
        "        words = [None] * (3 - len(words)) + words\n",
        "\n",
        "    for _ in range(max_length - len(words)):\n",
        "        # Try 4-gram first\n",
        "        history_4gram = tuple(words[-3:])\n",
        "        if history_4gram in fourgram_model:\n",
        "            next_word = random.choices(list(fourgram_model[history_4gram].keys()),\n",
        "                                        list(fourgram_model[history_4gram].values()))[0]\n",
        "        # Back off to Trigram\n",
        "        elif len(words) >= 2:\n",
        "            history_trigram = tuple(words[-2:])\n",
        "            if history_trigram in trigram_model:\n",
        "                next_word = random.choices(list(trigram_model[history_trigram].keys()),\n",
        "                                            list(trigram_model[history_trigram].values()))[0]\n",
        "            # Back off to Bigram\n",
        "            else:\n",
        "                history_bigram = tuple(words[-1:])\n",
        "                next_word = random.choices(list(bigram_model[history_bigram].keys()),\n",
        "                                            list(bigram_model[history_bigram].values()))[0]\n",
        "        else: # Default to random word\n",
        "            next_word = random.choice(tokens)\n",
        "\n",
        "        words.append(next_word)\n",
        "\n",
        "        # Stop at punctuation or word limit\n",
        "        if next_word in ['.', '?', '!']:\n",
        "            break\n",
        "\n",
        "    # Remove leading None values before joining\n",
        "    words = [w for w in words if w is not None]\n",
        "\n",
        "    return ' '.join(words).capitalize() + '.'"
      ],
      "metadata": {
        "id": "_Uh1bC-zoysi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build n-gram models\n",
        "bigram_model = build_ngram_model(tokens, 1)\n",
        "trigram_model = build_ngram_model(tokens, 2)\n",
        "fourgram_model = build_ngram_model(tokens, 3)\n",
        "print(\"N-gram models built successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "m0vXD2oZrHFg",
        "outputId": "b86330cb-d432-4e29-d89b-3dfb2b10eec2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N-gram models built successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "sentence1 = generate_sentence_with_backoff(\"the man\")\n",
        "print(sentence1)\n",
        "\n",
        "sentence2 = generate_sentence_with_backoff(\"her heart\")\n",
        "print(sentence2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "v4dX5ci2rLOs",
        "outputId": "cbb5f2fb-117b-4617-c05a-20319548bf2c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The man whom he so justly scorned from such a connection she could not.\n",
            "Her heart to jane though suspicion was very far from dreading a rebuke either.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio UI"
      ],
      "metadata": {
        "id": "kkUChnHJpRw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADIO UI\n",
        "with gr.Blocks(\n",
        "    theme=gr.themes.Soft(),\n",
        "    css=\"\"\"\n",
        "    .gradio-container {\n",
        "        background-color: #FFF5F2;\n",
        "    }\n",
        "\n",
        "    .gr-markdown h1 {\n",
        "        color: #568F87 !important;\n",
        "        font-family: Arial, sans-serif !important;\n",
        "        font-weight: bold !important;\n",
        "    }\n",
        "\n",
        "    .gr-markdown p {\n",
        "        color: #568F87 !important;\n",
        "    }\n",
        "\n",
        "    .gr-button {\n",
        "        background-color: #F5BABB !important;\n",
        "        color: #447D9B !important;\n",
        "    }\n",
        "\n",
        "    .gr-textbox input, .gr-textbox textarea {\n",
        "        color: black !important;\n",
        "    }\n",
        "\n",
        "    .made-by-text {\n",
        "        text-align: right;\n",
        "        color: black;\n",
        "    }\n",
        "\"\"\"\n",
        ") as demo:\n",
        "    gr.Markdown(\"â™¡ð“‚ƒðŸ–‹ The Austen EngineðŸ¤–\")\n",
        "    gr.Markdown(\"This language model generates sentences that mimic the writing style of Jane Austen using probabilistic n-gram models.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        start_words_input = gr.Textbox(\n",
        "            lines=1,\n",
        "            placeholder=\"e.g., The man\",\n",
        "            label=\"Starting Words\"\n",
        "        )\n",
        "\n",
        "    generate_button = gr.Button(\"Generate Sentence\")\n",
        "    output_text = gr.Textbox(label=\"Generated Sentence\")\n",
        "\n",
        "    generate_button.click(\n",
        "        fn=generate_sentence_with_backoff,\n",
        "        inputs=start_words_input,\n",
        "        outputs=output_text\n",
        "    )\n",
        "\n",
        "    gr.HTML(\"<p class='made-by-text'>Made by Reya Oberoi</p>\")\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "tiMaedrmsRAE",
        "outputId": "d0d0636f-ca0b-423c-8860-80846b61ba13"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b7409a21f81fa39b5c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b7409a21f81fa39b5c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}